.. ##
.. ## Copyright (c) 2016-18, Lawrence Livermore National Security, LLC.
.. ##
.. ## Produced at the Lawrence Livermore National Laboratory
.. ##
.. ## LLNL-CODE-689114
.. ##
.. ## All rights reserved.
.. ##
.. ## This file is part of RAJA.
.. ##
.. ## For details about use and distribution, please read RAJA/LICENSE.
.. ##

.. _addvectors-label:

--------------------------------------
Vector Addition (Basic Loop Execution)
--------------------------------------

Key RAJA features shown in this example:

  * ``RAJA::forall`` loop traversal template
  * ``RAJA::RangeSegment`` iteration space construct
  * RAJA execution policies


In the example, we add two vectors 'a' and 'b' of length N and
store the result in vector 'c'. A typical C-style that does this is:

.. literalinclude:: ../../../../examples/tut_add-vectors.cpp
                    :lines: 80-82

^^^^^^^^^^^^^^^^^^^^^
RAJA Variants
^^^^^^^^^^^^^^^^^^^^^

The RAJA variants of the vector addition operation illustrate how the 
same kernel can be run with a variety of different programming model
back-ends by simply swapping out the execution policy. This can be done
via type aliases in header file so the code can be parametrized to compile
differently without changing the kernel directly. In the example code, we
make all execution policy types explicit for clarity.

For the RAJA variants, we replace the C-style for-loop with a call to the 
``RAJA::forall`` loop traversal template method.
The method takes an iteration space and the vector addition loop body as
a C++ lambda function. Here, we pass a ``RAJA::RangeSegment`` object, which 
describes a contiguous sequence of integral values [0, N) for the iteration
space (for more information about RAJA loop index concepts, 
see :ref:`index-label`). The loop traversal template method requires an 
execution policy template type that specifies how the loop is to execute 
(for more information about RAJA execution policies, see :ref:`policies-label`).

For the RAJA sequential variant, we use the ``RAJA::seq_exec`` execution
policy:

.. literalinclude:: ../../../../examples/tut_add-vectors.cpp
                    :lines: 94-96

The RAJA sequential execution policy enforces strictly sequential execution; 
in particular, no SIMD vectorization instructions will be generated by the
compiler. To attempt to force the compiler to generated SIMD vectorization 
optimizations for a loop, we would use the SIMD execution policy:: 

  RAJA::simd_exec

Alternatively, RAJA provides a *loop execution* policy::

  RAJA::loop_exec

This policy allows the compiler to generate optimizations, such as SIMD if 
compiler heuristics suggest that it is safe to do so, but the optimizations
are not forced.

To run the kernel with OpenMP multi-threaded parallelism on a CPU, we use the
``RAJA::omp_parallel_for_exec`` execution policy:

.. literalinclude:: ../../../../examples/tut_add-vectors.cpp
                    :lines: 137-139

Finally, to run the kernel on a CUDA GPU device, we use the ``RAJA::cuda_exec``
policy:

.. literalinclude:: ../../../../examples/tut_add-vectors.cpp
                    :lines: 151-154

Note that the CUDA execution policy type accepts a template argument 
``CUDA_BLOCK_SIZE``, which we've defined to be an integral value of 256
in the example. This means that each CUDA thread block that is launched to 
execute the kernel will have 256 threads in the block. The thread block size
parameter is optional; if not specified the RAJA policy provides a default of
256, which is reasonable for most cases. 

Since the lambda defining the loop body will be passed to a device kernel, 
it must be decorated with the ``__device__`` attribute when it is defined. 
This can be done directly or by using the ``RAJA_DEVICE`` macro.

The file ``RAJA/examples/tut_add-vectors.cpp`` contains the complete 
working example code.
